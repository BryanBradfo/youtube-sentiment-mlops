import pandas as pd
import torch
from transformers import pipeline
import emoji
from tqdm import tqdm

# --- Configuration ---
INPUT_FILE = "commentaires_youtube.csv"
OUTPUT_FILE = "commentaires_youtube_sentiments.csv"
# Le traitement par lots est crucial pour ne pas saturer la VRAM de 8GB.
# Ajustez cette valeur si vous rencontrez des erreurs de m√©moire.
BATCH_SIZE = 32 

# --- Fonctions ---

def preprocess_comment(text):
    """
    Nettoie et pr√©pare le texte du commentaire.
    Convertit les emojis en leur description textuelle.
    """
    if not isinstance(text, str):
        return ""
    # Convertit les emojis en texte (ex: "üòÇ" -> ":face_with_tears_of_joy:")
    return emoji.demojize(text, language='fr')

def map_sentiment_labels(label):
    """
    Traduit les labels du mod√®le en cat√©gories simples.
    Le mod√®le 'nlptown/bert-base-multilingual-uncased-sentiment' retourne des √©toiles.
    """
    if label in ["1 star", "2 stars"]:
        return "N√©gatif"
    elif label == "3 stars":
        return "Neutre"
    elif label in ["4 stars", "5 stars"]:
        return "Positif"
    return "Ind√©termin√©"


def main():
    """
    Fonction principale pour charger les donn√©es, analyser les sentiments et sauvegarder.
    """
    # 1. V√©rifier la disponibilit√© du GPU
    if not torch.cuda.is_available():
        print("Attention : Le GPU n'est pas disponible. Le traitement se fera sur CPU et sera tr√®s lent.")
        device = -1 # Utiliser le CPU
    else:
        print(f"GPU d√©tect√© : {torch.cuda.get_device_name(0)}")
        device = 0 # Utiliser le premier GPU

    # 2. Charger les donn√©es
    try:
        df = pd.read_csv(INPUT_FILE)
        print(f"Fichier '{INPUT_FILE}' charg√©. {len(df)} commentaires √† analyser.")
    except FileNotFoundError:
        print(f"Erreur : Le fichier '{INPUT_FILE}' n'a pas √©t√© trouv√©.")
        return

    # 3. Pr√©parer le mod√®le
    print("Chargement du mod√®le d'analyse de sentiments...")
    # Mod√®le multilingue, l√©ger et efficace, parfait pour notre cas d'usage.
    sentiment_pipeline = pipeline(
        "sentiment-analysis", 
        model="nlptown/bert-base-multilingual-uncased-sentiment",
        device=device
    )
    print("Mod√®le charg√©.")

    # 4. Pr√©-traiter les commentaires
    print("Pr√©-traitement des commentaires (conversion des emojis)...")
    commentaires = df['commentaire'].apply(preprocess_comment).tolist()

    # 5. Analyser les sentiments par lots (batching)
    print(f"D√©but de l'analyse des sentiments par lots de {BATCH_SIZE}...")
    all_results = []
    # tqdm ajoute une barre de progression tr√®s pratique
    for i in tqdm(range(0, len(commentaires), BATCH_SIZE), desc="Analyse des lots"):
        batch = commentaires[i:i + BATCH_SIZE]
        results = sentiment_pipeline(batch)
        all_results.extend(results)

    # 6. Ajouter les r√©sultats au DataFrame
    sentiments = [res['label'] for res in all_results]
    scores = [res['score'] for res in all_results]
    
    df['sentiment_label'] = sentiments
    df['sentiment_score'] = scores
    df['sentiment_categorie'] = df['sentiment_label'].apply(map_sentiment_labels)

    # 7. Sauvegarder le nouveau fichier CSV
    try:
        df.to_csv(OUTPUT_FILE, index=False, encoding='utf-8-sig')
        print(f"\nAnalyse termin√©e ! Les r√©sultats ont √©t√© sauvegard√©s dans '{OUTPUT_FILE}'.")
        print("\nAper√ßu des r√©sultats :")
        print(df[['commentaire', 'sentiment_categorie', 'sentiment_score']].head())
    except Exception as e:
        print(f"Erreur lors de la sauvegarde du fichier : {e}")


if __name__ == "__main__":
    main()