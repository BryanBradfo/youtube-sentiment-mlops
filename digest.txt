Directory structure:
└── Youtube/
    ├── Dockerfile
    ├── dvc.lock
    ├── dvc.yaml
    ├── environment.yml
    ├── .dvcignore
    ├── mlruns/
    │   ├── 0/
    │   │   └── meta.yaml
    │   ├── 465651618208328789/
    │   │   ├── meta.yaml
    │   │   ├── a8636f253f664eb9bc055448b34169ca/
    │   │   │   ├── meta.yaml
    │   │   │   ├── metrics/
    │   │   │   │   └── accuracy
    │   │   │   └── tags/
    │   │   │       ├── mlflow.runName
    │   │   │       ├── mlflow.source.git.commit
    │   │   │       ├── mlflow.source.name
    │   │   │       └── mlflow.source.type
    │   │   ├── c05b2b2aca8345c1949747521a413d72/
    │   │   │   ├── meta.yaml
    │   │   │   ├── outputs/
    │   │   │   │   └── m-b01581406cb34463ae8d772e2eed87ea/
    │   │   │   │       └── meta.yaml
    │   │   │   ├── params/
    │   │   │   │   ├── base_model
    │   │   │   │   ├── ngram_range
    │   │   │   │   └── vect_max_features
    │   │   │   └── tags/
    │   │   │       ├── mlflow.runName
    │   │   │       ├── mlflow.source.git.commit
    │   │   │       ├── mlflow.source.name
    │   │   │       └── mlflow.source.type
    │   │   └── models/
    │   │       └── m-b01581406cb34463ae8d772e2eed87ea/
    │   │           ├── meta.yaml
    │   │           ├── artifacts/
    │   │           │   ├── conda.yaml
    │   │           │   ├── MLmodel
    │   │           │   ├── model.pkl
    │   │           │   ├── python_env.yaml
    │   │           │   └── requirements.txt
    │   │           ├── params/
    │   │           │   ├── base_model
    │   │           │   ├── ngram_range
    │   │           │   └── vect_max_features
    │   │           └── tags/
    │   │               ├── mlflow.modelVersions
    │   │               ├── mlflow.source.git.commit
    │   │               ├── mlflow.source.name
    │   │               └── mlflow.source.type
    │   └── models/
    │       └── SentimentStack/
    │           ├── meta.yaml
    │           └── version-1/
    │               └── meta.yaml
    ├── src/
    │   ├── annotate.py
    │   ├── fetch_comments.py
    │   ├── preprocess.py
    │   └── train_stack.py
    ├── tests/
    │   └── test_preprocess.py
    ├── .dvc/
    │   └── config
    └── .github/
        └── workflows/
            └── main.yml

================================================
FILE: Dockerfile
================================================
# Ã‰tape 1: Utiliser une image de base avec Conda
FROM continuumio/miniconda3

# DÃ©finir le rÃ©pertoire de travail dans le conteneur
WORKDIR /app

# Copier les fichiers de dÃ©pendances et crÃ©er l'environnement
# On installe la version CPU de PyTorch car c'est le cas le plus courant pour un dÃ©ploiement sans GPU
COPY environment.yml ./
RUN conda env create -f environment.yml && \
    conda run -n sentiment-mlops pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cpu

# Copier tout le reste du projet
COPY . .

# DÃ©finir le point d'entrÃ©e pour lancer la pipeline.
# --no-capture-output est utile pour voir les prints de vos scripts en temps rÃ©el.
ENTRYPOINT ["conda", "run", "--no-capture-output", "-n", "sentiment-mlops", "dvc", "repro"]


================================================
FILE: dvc.lock
================================================
schema: '2.0'
stages:
  fetch:
    cmd: python src/fetch_comments.py
    outs:
    - path: data/raw/commentaires_youtube.csv
      hash: md5
      md5: 3b37df224a4b26cf6ee357c8f81bdd2c
      size: 1057608
  preprocess:
    cmd: python src/preprocess.py
    deps:
    - path: data/raw/commentaires_youtube.csv
      hash: md5
      md5: 3b37df224a4b26cf6ee357c8f81bdd2c
      size: 1057608
    - path: src/preprocess.py
      hash: md5
      md5: 927c0fc5548db72052bd99f860d32af8
      size: 951
    outs:
    - path: data/processed/commentaires_clean.csv
      hash: md5
      md5: a5f7fcca01f98e4e515f9cbf1f1304b8
      size: 1688263
  annotate:
    cmd: python src/annotate.py
    deps:
    - path: data/processed/commentaires_clean.csv
      hash: md5
      md5: a5f7fcca01f98e4e515f9cbf1f1304b8
      size: 1688263
    - path: src/annotate.py
      hash: md5
      md5: c29c12eb0932b015219524c601fad4fc
      size: 1565
    outs:
    - path: data/processed/commentaires_sentiment.csv
      hash: md5
      md5: d4d19c539fedc2082cb775e55d8e6217
      size: 1962709
  train:
    cmd: python src/train_stack.py
    deps:
    - path: data/processed/commentaires_sentiment.csv
      hash: md5
      md5: d4d19c539fedc2082cb775e55d8e6217
      size: 1962709
    - path: src/train_stack.py
      hash: md5
      md5: e924aaccbb05367cb585ec860d104a86
      size: 2264



================================================
FILE: dvc.yaml
================================================
stages:
  fetch:
    cmd: python src/fetch_comments.py
    deps: []
    outs:
      - data/raw/commentaires_youtube.csv
  preprocess:
    cmd: python src/preprocess.py
    deps:
      - data/raw/commentaires_youtube.csv
      - src/preprocess.py
    outs:
      - data/processed/commentaires_clean.csv
  annotate:
    cmd: python src/annotate.py
    deps:
      - data/processed/commentaires_clean.csv
      - src/annotate.py
    outs:
      - data/processed/commentaires_sentiment.csv
  train:
    cmd: python src/train_stack.py
    deps:
      - data/processed/commentaires_sentiment.csv
      - src/train_stack.py
    # Pas de section 'outs'. MLflow s'occupe du modÃ¨le.


================================================
FILE: environment.yml
================================================
name: sentiment-mlops
channels:
  - conda-forge
  - defaults
dependencies:
  - python=3.10
  - pip
  - pandas
  - scikit-learn
  - dvc
  - mlflow
  - pytest 
  - flake8
  - pip:
    - google-api-python-client
    - python-dotenv
    - emoji
    - sentencepiece
    - transformers
    - tiktoken


================================================
FILE: .dvcignore
================================================
# Add patterns of files dvc should ignore, which could improve
# the performance. Learn more at
# https://dvc.org/doc/user-guide/dvcignore



================================================
FILE: mlruns/0/meta.yaml
================================================
artifact_location: mlflow-artifacts:/0
creation_time: 1752399723401
experiment_id: '0'
last_update_time: 1752399723401
lifecycle_stage: active
name: Default



================================================
FILE: mlruns/465651618208328789/meta.yaml
================================================
artifact_location: file:///C:/Users/Bradf/Desktop/Work/Projets/Youtube/mlruns/465651618208328789
creation_time: 1752399814295
experiment_id: '465651618208328789'
last_update_time: 1752399814295
lifecycle_stage: active
name: sentiment-stack



================================================
FILE: mlruns/465651618208328789/a8636f253f664eb9bc055448b34169ca/meta.yaml
================================================
artifact_uri: file:///C:/Users/Bradf/Desktop/Work/Projets/Youtube/mlruns/465651618208328789/a8636f253f664eb9bc055448b34169ca/artifacts
end_time: 1752399820380
entry_point_name: ''
experiment_id: '465651618208328789'
lifecycle_stage: active
run_id: a8636f253f664eb9bc055448b34169ca
run_name: enchanting-shad-382
source_name: ''
source_type: 4
source_version: ''
start_time: 1752399820293
status: 3
tags: []
user_id: Bradf



================================================
FILE: mlruns/465651618208328789/a8636f253f664eb9bc055448b34169ca/metrics/accuracy
================================================
1752399820374 0.7662271805273834 0



================================================
FILE: mlruns/465651618208328789/a8636f253f664eb9bc055448b34169ca/tags/mlflow.runName
================================================
enchanting-shad-382


================================================
FILE: mlruns/465651618208328789/a8636f253f664eb9bc055448b34169ca/tags/mlflow.source.git.commit
================================================
c2808a0ddac318cf7aa88fa1ee5b21d311110344


================================================
FILE: mlruns/465651618208328789/a8636f253f664eb9bc055448b34169ca/tags/mlflow.source.name
================================================
src/train_stack.py


================================================
FILE: mlruns/465651618208328789/a8636f253f664eb9bc055448b34169ca/tags/mlflow.source.type
================================================
LOCAL


================================================
FILE: mlruns/465651618208328789/c05b2b2aca8345c1949747521a413d72/meta.yaml
================================================
artifact_uri: file:///C:/Users/Bradf/Desktop/Work/Projets/Youtube/mlruns/465651618208328789/c05b2b2aca8345c1949747521a413d72/artifacts
end_time: 1752399820223
entry_point_name: ''
experiment_id: '465651618208328789'
lifecycle_stage: active
run_id: c05b2b2aca8345c1949747521a413d72
run_name: clumsy-bird-12
source_name: ''
source_type: 4
source_version: ''
start_time: 1752399814565
status: 3
tags: []
user_id: Bradf



================================================
FILE: mlruns/465651618208328789/c05b2b2aca8345c1949747521a413d72/outputs/m-b01581406cb34463ae8d772e2eed87ea/meta.yaml
================================================
destination_id: m-b01581406cb34463ae8d772e2eed87ea
destination_type: MODEL_OUTPUT
source_id: m-b01581406cb34463ae8d772e2eed87ea
source_type: RUN_OUTPUT
step: 0
tags: {}



================================================
FILE: mlruns/465651618208328789/c05b2b2aca8345c1949747521a413d72/params/base_model
================================================
LogisticRegression


================================================
FILE: mlruns/465651618208328789/c05b2b2aca8345c1949747521a413d72/params/ngram_range
================================================
(1,2)


================================================
FILE: mlruns/465651618208328789/c05b2b2aca8345c1949747521a413d72/params/vect_max_features
================================================
5000


================================================
FILE: mlruns/465651618208328789/c05b2b2aca8345c1949747521a413d72/tags/mlflow.runName
================================================
clumsy-bird-12


================================================
FILE: mlruns/465651618208328789/c05b2b2aca8345c1949747521a413d72/tags/mlflow.source.git.commit
================================================
c2808a0ddac318cf7aa88fa1ee5b21d311110344


================================================
FILE: mlruns/465651618208328789/c05b2b2aca8345c1949747521a413d72/tags/mlflow.source.name
================================================
src/train_stack.py


================================================
FILE: mlruns/465651618208328789/c05b2b2aca8345c1949747521a413d72/tags/mlflow.source.type
================================================
LOCAL


================================================
FILE: mlruns/465651618208328789/models/m-b01581406cb34463ae8d772e2eed87ea/meta.yaml
================================================
artifact_location: file:///C:/Users/Bradf/Desktop/Work/Projets/Youtube/mlruns/465651618208328789/models/m-b01581406cb34463ae8d772e2eed87ea/artifacts
creation_timestamp: 1752399816103
experiment_id: '465651618208328789'
last_updated_timestamp: 1752399820141
model_id: m-b01581406cb34463ae8d772e2eed87ea
model_type: null
name: stacking_model
source_run_id: c05b2b2aca8345c1949747521a413d72
status: 2
status_message: null



================================================
FILE: mlruns/465651618208328789/models/m-b01581406cb34463ae8d772e2eed87ea/artifacts/conda.yaml
================================================
channels:
- conda-forge
dependencies:
- python=3.10.18
- pip<=25.1.1
- pip:
  - mlflow==3.1.2
  - cloudpickle==3.1.1
  - numpy==2.2.6
  - packaging==24.2
  - pandas==2.3.1
  - psutil==7.0.0
  - pyyaml==6.0.2
  - scikit-learn==1.7.0
  - scipy==1.15.2
name: mlflow-env



================================================
FILE: mlruns/465651618208328789/models/m-b01581406cb34463ae8d772e2eed87ea/artifacts/MLmodel
================================================
artifact_path: file:///C:/Users/Bradf/Desktop/Work/Projets/Youtube/mlruns/465651618208328789/models/m-b01581406cb34463ae8d772e2eed87ea/artifacts
flavors:
  python_function:
    env:
      conda: conda.yaml
      virtualenv: python_env.yaml
    loader_module: mlflow.sklearn
    model_path: model.pkl
    predict_fn: predict
    python_version: 3.10.18
  sklearn:
    code: null
    pickled_model: model.pkl
    serialization_format: cloudpickle
    sklearn_version: 1.7.0
mlflow_version: 3.1.2
model_id: m-b01581406cb34463ae8d772e2eed87ea
model_size_bytes: 241798
model_uuid: m-b01581406cb34463ae8d772e2eed87ea
prompts: null
run_id: c05b2b2aca8345c1949747521a413d72
utc_time_created: '2025-07-13 09:43:36.146502'



================================================
FILE: mlruns/465651618208328789/models/m-b01581406cb34463ae8d772e2eed87ea/artifacts/model.pkl
================================================
[Non-text file]


================================================
FILE: mlruns/465651618208328789/models/m-b01581406cb34463ae8d772e2eed87ea/artifacts/python_env.yaml
================================================
python: 3.10.18
build_dependencies:
- pip==25.1.1
- setuptools==80.9.0
- wheel==0.45.1
dependencies:
- -r requirements.txt



================================================
FILE: mlruns/465651618208328789/models/m-b01581406cb34463ae8d772e2eed87ea/artifacts/requirements.txt
================================================
mlflow==3.1.2
cloudpickle==3.1.1
numpy==2.2.6
packaging==24.2
pandas==2.3.1
psutil==7.0.0
pyyaml==6.0.2
scikit-learn==1.7.0
scipy==1.15.2


================================================
FILE: mlruns/465651618208328789/models/m-b01581406cb34463ae8d772e2eed87ea/params/base_model
================================================
LogisticRegression


================================================
FILE: mlruns/465651618208328789/models/m-b01581406cb34463ae8d772e2eed87ea/params/ngram_range
================================================
(1,2)


================================================
FILE: mlruns/465651618208328789/models/m-b01581406cb34463ae8d772e2eed87ea/params/vect_max_features
================================================
5000


================================================
FILE: mlruns/465651618208328789/models/m-b01581406cb34463ae8d772e2eed87ea/tags/mlflow.modelVersions
================================================
[{"name": "SentimentStack", "version": 1}]


================================================
FILE: mlruns/465651618208328789/models/m-b01581406cb34463ae8d772e2eed87ea/tags/mlflow.source.git.commit
================================================
c2808a0ddac318cf7aa88fa1ee5b21d311110344


================================================
FILE: mlruns/465651618208328789/models/m-b01581406cb34463ae8d772e2eed87ea/tags/mlflow.source.name
================================================
src/train_stack.py


================================================
FILE: mlruns/465651618208328789/models/m-b01581406cb34463ae8d772e2eed87ea/tags/mlflow.source.type
================================================
LOCAL


================================================
FILE: mlruns/models/SentimentStack/meta.yaml
================================================
aliases: {}
creation_timestamp: 1752399820177
deployment_job_id: null
deployment_job_state: null
description: null
last_updated_timestamp: 1752399820180
name: SentimentStack



================================================
FILE: mlruns/models/SentimentStack/version-1/meta.yaml
================================================
aliases: []
creation_timestamp: 1752399820180
current_stage: None
deployment_job_state: null
description: null
last_updated_timestamp: 1752399820180
metrics: null
model_id: m-b01581406cb34463ae8d772e2eed87ea
name: SentimentStack
params: null
run_id: c05b2b2aca8345c1949747521a413d72
run_link: null
source: models:/m-b01581406cb34463ae8d772e2eed87ea
status: READY
status_message: null
storage_location: file:///C:/Users/Bradf/Desktop/Work/Projets/Youtube/mlruns/465651618208328789/models/m-b01581406cb34463ae8d772e2eed87ea/artifacts
user_id: null
version: 1



================================================
FILE: src/annotate.py
================================================
import os
import pandas as pd
import torch
from transformers import XLMRobertaTokenizer, XLMRobertaForSequenceClassification, pipeline

INPUT_CSV  = "data/processed/commentaires_clean.csv"
OUTPUT_CSV = "data/processed/commentaires_sentiment.csv"

def annotate_sentiment(df: pd.DataFrame) -> pd.DataFrame:
    # Choix du device GPU si disponible, sinon CPU
    device = 0 if torch.cuda.is_available() else -1
    print(f"Using device: {'GPU' if device == 0 else 'CPU'}")

    # Chargement du tokenizer et du modÃ¨le lents
    tokenizer = XLMRobertaTokenizer.from_pretrained(
        "cardiffnlp/twitter-xlm-roberta-base-sentiment"
    )
    model = XLMRobertaForSequenceClassification.from_pretrained(
        "cardiffnlp/twitter-xlm-roberta-base-sentiment"
    )

    sentiment_pipe = pipeline(
        "sentiment-analysis",
        model=model,
        tokenizer=tokenizer,
        device=device
    )

    labels, scores = [], []
    # Conversion des NaN en chaÃ®ne vide et forÃ§age en str
    for txt in df["commentaire_clean"].fillna("").astype(str).tolist():
        res = sentiment_pipe(txt[:512])[0]
        labels.append(res["label"])
        scores.append(res["score"])

    df["sentiment"] = labels
    df["score"]     = scores
    return df

if __name__ == "__main__":
    os.makedirs(os.path.dirname(OUTPUT_CSV), exist_ok=True)
    df = pd.read_csv(INPUT_CSV)
    df = annotate_sentiment(df)
    df.to_csv(OUTPUT_CSV, index=False, encoding="utf-8-sig")
    print(f"Annotation sentiment OK â†’ {OUTPUT_CSV}")



================================================
FILE: src/fetch_comments.py
================================================
import os
import pandas as pd
from googleapiclient.discovery import build
from dotenv import load_dotenv
load_dotenv()

API_KEY    = os.getenv("YOUTUBE_API_KEY")
print("ðŸ”‘ API_KEY chargÃ©e :", API_KEY)

VIDEO_ID   = "ClF55GE7zPI"
OUTPUT_CSV = "data/raw/commentaires_youtube.csv"

def fetch_comments(api_key: str, video_id: str) -> pd.DataFrame:
    yt = build("youtube", "v3", developerKey=api_key)
    all_comments = []
    req = yt.commentThreads().list(
        part="snippet",
        videoId=video_id,
        textFormat="plainText",
        maxResults=100
    )
    while req:
        res = req.execute()
        for item in res["items"]:
            s = item["snippet"]["topLevelComment"]["snippet"]
            all_comments.append({
                "auteur":          s["authorDisplayName"],
                "commentaire":     s["textDisplay"],
                "likes":           s["likeCount"],
                "date_publication":s["publishedAt"]
            })
        req = yt.commentThreads().list_next(req, res)
    return pd.DataFrame(all_comments)

if __name__ == "__main__":
    os.makedirs(os.path.dirname(OUTPUT_CSV), exist_ok=True)
    df = fetch_comments(API_KEY, VIDEO_ID)
    df.to_csv(OUTPUT_CSV, index=False, encoding="utf-8-sig")
    print(f"{len(df)} commentaires sauvegardÃ©s dans {OUTPUT_CSV}")



================================================
FILE: src/preprocess.py
================================================
import os
import pandas as pd
import re
import emoji

INPUT_CSV  = "data/raw/commentaires_youtube.csv"
OUTPUT_CSV = "data/processed/commentaires_clean.csv"

def strip_emojis(text: str) -> str:
    counter = {"i": 0}
    def replace_func(emj_char, emj_data):
        counter["i"] += 1
        return f"<EMOJI_{counter['i']}>"
    return emoji.replace_emoji(text, replace_func)

def clean_text(text: str) -> str:
    text = text.lower()
    text = re.sub(r"http\S+", "", text)
    text = re.sub(r"@\w+", "", text)
    text = strip_emojis(text)
    text = re.sub(r"[^a-z0-9_<>\s]+", "", text)
    return text.strip()

if __name__ == "__main__":
    os.makedirs(os.path.dirname(OUTPUT_CSV), exist_ok=True)
    df = pd.read_csv(INPUT_CSV)
    df["commentaire_clean"] = df["commentaire"].astype(str).apply(clean_text)
    df.to_csv(OUTPUT_CSV, index=False, encoding="utf-8-sig")
    print(f"PrÃ©traitement OK â†’ {OUTPUT_CSV}")



================================================
FILE: src/train_stack.py
================================================
import mlflow
import mlflow.sklearn
import pandas as pd
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import StackingClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report

# Chemin du dataset annotÃ©
DATA_CSV = "data/processed/commentaires_sentiment.csv"


def load_data():
    # Chargement et nettoyage des NaN
    df = pd.read_csv(DATA_CSV)
    df = df.dropna(subset=["commentaire_clean", "sentiment"])
    X = df["commentaire_clean"]
    y = df["sentiment"]
    return train_test_split(X, y, test_size=0.2, random_state=42)


def build_and_train(X_train, y_train):
    # TF-IDF vectorisation
    tfidf = TfidfVectorizer(max_features=5000, ngram_range=(1,2))
    X_vec = tfidf.fit_transform(X_train)

    # ModÃ¨le de base et stacking
    lr = LogisticRegression(max_iter=1000)
    stack = StackingClassifier(
        estimators=[("lr", lr)],
        final_estimator=LogisticRegression(),
        passthrough=True
    )

    mlflow.set_experiment("sentiment-stack")
    with mlflow.start_run():
        # Log des paramÃ¨tres
        mlflow.log_params({
            "vect_max_features": 5000,
            "ngram_range": "(1,2)",
            "base_model": "LogisticRegression"
        })
        # EntraÃ®nement
        stack.fit(X_vec, y_train)
        # Enregistrement du modÃ¨le dans MLflow et registre
        mlflow.sklearn.log_model(
            sk_model=stack,
            artifact_path="stacking_model",
            registered_model_name="SentimentStack"
        )
        return tfidf, stack


def evaluate(tfidf, model, X_test, y_test):
    # Ã‰valuation
    X_vec = tfidf.transform(X_test)
    preds = model.predict(X_vec)
    print(classification_report(y_test, preds))
    mlflow.log_metric("accuracy", float((preds == y_test).mean()))


if __name__ == "__main__":
    # Chargement des donnÃ©es
    X_train, X_test, y_train, y_test = load_data()
    # EntraÃ®nement
    tfidf, model = build_and_train(X_train, y_train)
    # Ã‰valuation
    evaluate(tfidf, model, X_test, y_test)
    print("EntraÃ®nement et Ã©valuation terminÃ©s.")



================================================
FILE: tests/test_preprocess.py
================================================
# tests/test_preprocess.py
import sys
import os

# Ajoute le dossier 'src' au chemin pour que Python puisse trouver 'preprocess'
sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), '../src')))

from preprocess import clean_text

def test_clean_text():
    """VÃ©rifie que le nettoyage de base fonctionne."""
    input_text = "Super vidÃ©o @Squeezie ! Regardez Ã§a https://t.co/xyz"
    expected_output = "super vidÃ©o  regardez Ã§a"
    assert clean_text(input_text) == expected_output

def test_strip_emojis():
    """VÃ©rifie que les emojis sont bien remplacÃ©s."""
    input_text = "J'adore cette vidÃ©o ðŸ˜‚"
    expected_output = "jadore cette vidÃ©o <emoji_1>"
    # Note : Le vrai nom de l'emoji peut varier, on vÃ©rifie juste le format
    assert "<emoji_1>" in clean_text(input_text)


================================================
FILE: .dvc/config
================================================
[core]
    remote = myremote
['remote "myremote"']
    url = gdrive://1KjF2GybzbLDqvDVlWIIUXo0b2OaVYiiM



================================================
FILE: .github/workflows/main.yml
================================================
name: CI - Validation de la Pipeline ML

on:
  push:
    branches: [ main, master ]
  pull_request:
    branches: [ main, master ]

jobs:
  validate-pipeline:
    runs-on: ubuntu-latest

    steps:
      # Ã‰tape 1: RÃ©cupÃ©rer le code du dÃ©pÃ´t
      - name: Checkout repository
        uses: actions/checkout@v3

      # Ã‰tape 2: Mettre en place Conda et crÃ©er l'environnement
      # C'est plus rapide que de construire une image Docker Ã  chaque fois.
      - name: Setup Miniconda
        uses: conda-incubator/setup-miniconda@v2
        with:
          auto-activate-base: false
          activate-environment: sentiment-mlops
          environment-file: environment.yml
          # Installe la version CPU de PyTorch car les runners GitHub n'ont pas de GPU
          python-version: "3.10"

      # Ã‰tape 3: Linter le code avec Flake8 pour assurer la qualitÃ©
      - name: Lint code with Flake8
        run: |
          # Le shell est dÃ©jÃ  configurÃ© par setup-miniconda pour utiliser l'env activÃ©
          flake8 src/ tests/

      # Ã‰tape 4: Lancer les tests unitaires avec Pytest
      - name: Run unit tests
        run: |
          pytest

      # Ã‰tape 5: Lancer la pipeline DVC complÃ¨te pour s'assurer qu'elle fonctionne
      # On ne fait pas de "dvc pull" car nous n'avons pas de remote.
      # La pipeline va commencer de zÃ©ro, ce qui est parfait pour un test.
      - name: Run DVC pipeline from scratch
        env:
          # On passe la clÃ© API de maniÃ¨re sÃ©curisÃ©e via les secrets GitHub
          YOUTUBE_API_KEY: ${{ secrets.YOUTUBE_API_KEY }}
        run: |
          # DVC a besoin de cette variable dans un fichier .env
          echo "YOUTUBE_API_KEY=${YOUTUBE_API_KEY}" > .env
          dvc repro

